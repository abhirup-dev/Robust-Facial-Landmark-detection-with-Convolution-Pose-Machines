{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove boxes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.ndimage.interpolation import zoom \n",
    "import numbers, math\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from datasets.point_meta import Point_Meta\n",
    "import os \n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from utils import generate_label_map_laplacian\n",
    "from utils import generate_label_map_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(file_path):\n",
    "    '''\n",
    "    load data or string from text file.\n",
    "    '''\n",
    "    file_path = osp.normpath(file_path)\n",
    "    assert osp.exists(file_path), 'text file is not existing!'\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read().splitlines()\n",
    "    num_lines = len(data)\n",
    "    file.close()\n",
    "    return data, num_lines\n",
    "def annot_parser_300W(anno_path, n_pts):  \n",
    "    data = load_txt_file(anno_path)[0]\n",
    "    points = np.zeros((3,n_pts), dtype='float32')\n",
    "    point_set = set()\n",
    "    offset = 3\n",
    "    for idx in range(n_pts):\n",
    "        line = data[idx+offset].split(' ')\n",
    "        if len(line) > 2 : line.remove(' ')\n",
    "        points[0, idx] = float(line[0])\n",
    "        points[1, idx] = float(line[1])\n",
    "        points[2, idx] = float(1)\n",
    "        point_set.add(idx)\n",
    "    return points, point_set\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenDataset(data.Dataset):\n",
    "    def __init__(self, transform, sigma, downsample, heatmap_type, dataset_name):\n",
    "        self.transform = transform\n",
    "        self.sigma = sigma\n",
    "        self.downsample = downsample\n",
    "        self.heatmap_type = heatmap_type\n",
    "        self.dataset_name = dataset_name\n",
    "        self.reset()\n",
    "        print ('The general dataset initialization done, sigma is {}, downsample is {}, dataset-name : {}, self is : {}'.format(sigma, downsample, dataset_name, self))\n",
    "    def reset(self, num_pts=68):\n",
    "        self.length = 0\n",
    "        self.NUM_PTS = num_pts\n",
    "        self.datas = []\n",
    "        self.labels = []\n",
    "        self.face_sizes = []\n",
    "        assert self.dataset_name is not None, 'The dataset name is None'  \n",
    "    \n",
    "    def load_list(self,train_list_file_paths, num_pts):#Extracts labels,boxes,faces information of training data\n",
    "        if isinstance(train_list_file_paths, str) :\n",
    "            train_list_file_paths = [train_list_file_paths]\n",
    "        datas, labels, boxes, face_sizes = [], [], [], []\n",
    "        for file_idx, file_path in enumerate(train_list_file_paths):\n",
    "            train_list_file = open(file_path)\n",
    "            train_list_data = train_list_file.read().splitlines()\n",
    "            train_list_file.close()\n",
    "            print(len(train_list_data))\n",
    "            for jdx, data in enumerate(train_list_data):\n",
    "                alls = data.split(' ')\n",
    "                if '' in alls: alls.remove('')\n",
    "                assert len(alls) == 6 or len(alls) == 7, 'The {:04d}-th line is wrong : {:}'.format(idx, data)\n",
    "                datas.append(alls[0])\n",
    "                if alls[1] == None:\n",
    "                    labels.append(None)\n",
    "                else: labels.append(alls[1])\n",
    "                box = np.array( [ float(alls[2]), float(alls[3]), float(alls[4]), float(alls[5]) ] )\n",
    "                boxes.append( box )\n",
    "                if len(alls) == 6:\n",
    "                    face_sizes.append( None )\n",
    "                else:\n",
    "                    face_sizes.append( float(alls[6]) )\n",
    "        #     print(len(alls))\n",
    "        self.load_data(datas, labels, boxes, face_sizes, num_pts)\n",
    "        \n",
    "    def load_data(self, datas, labels, boxes, face_sizes, num_pts):# Loads images, labels, boxes\n",
    "        print ('Start load data for the general datas')\n",
    "        assert isinstance(datas, list), 'The type of the datas is not correct : {}'.format( type(datas) )\n",
    "        assert isinstance(labels, list) and len(datas) == len(labels), 'The type of the labels is not correct : {}'.format( type(labels) )\n",
    "        assert isinstance(boxes, list) and len(datas) == len(boxes), 'The type of the boxes is not correct : {}'.format( type(boxes) )\n",
    "        assert isinstance(face_sizes, list) and len(datas) == len(face_sizes), 'The type of the face_sizes is not correct : {}'.format( type(face_sizes) )\n",
    "        assert num_pts == 68, 'The number of point is inconsistent : {} vs {}'.format(68, num_pts)\n",
    "        \n",
    "        for idx, data in enumerate(datas):\n",
    "            assert isinstance(data, str), 'The type of data is not correct : {}'.format(data)\n",
    "            assert osp.isfile(datas[idx]), '{} is not a file'.format(datas[idx])\n",
    "            self.append(datas[idx], labels[idx], boxes[idx], face_sizes[idx])\n",
    "            \n",
    "        assert len(self.datas) == self.length, 'The length and the data is not right {} vs {}'.format(self.length, len(self.datas))   \n",
    "        assert len(self.labels) == self.length, 'The length and the labels is not right {} vs {}'.format(self.length, len(self.labels))\n",
    "        assert len(self.face_sizes) == self.length, 'The length and the face_sizes is not right {} vs {}'.format(self.length, len(self.face_sizes))\n",
    "        print ('Load data done for the general dataset, which has {} images.'.format(self.length))\n",
    "        \n",
    "    def append(self, data, label, box, face_size):\n",
    "        assert osp.isfile(data), 'The image path is not a file {}'.format(data)\n",
    "        assert osp.isfile(label), 'The label path is not a file {}'.format(label)\n",
    "        self.datas.append(data)\n",
    "        np_points,_ = annot_parser_300W(label, self.NUM_PTS)\n",
    "        meta = Point_Meta(self.NUM_PTS, np_points, box, data, self.dataset_name)\n",
    "        self.labels.append(meta)\n",
    "        self.face_sizes.append(face_size)\n",
    "        self.length += 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = pil_loader( self.datas[index] )\n",
    "        xtarget = self.labels[index].copy()\n",
    "        return self._process_(image, xtarget, index)\n",
    "    def __len__(self):\n",
    "        return self.length \n",
    "    \n",
    "    def _process_(self, image, xtarget, index):\n",
    "        visible = xtarget.points[2,:].astype('bool')\n",
    "        if self.transform is not None:\n",
    "            image, xtarget = self.transform(image, xtarget)\n",
    "#         temp_save_wh = xtarget.temp_save_wh\n",
    "        \n",
    "#         ori_size = torch.IntTensor( [temp_save_wh[1], temp_save_wh[0], temp_save_wh[2], temp_save_wh[3]] ) # H, W, Cropped_[x1,y1]\n",
    "    \n",
    "        if isinstance(image, Image.Image):\n",
    "            height, width = image.size[1], image.size[0]\n",
    "#             print('Image converted to Tensor using transforms')\n",
    "            trans = transforms.ToTensor()\n",
    "            image = trans(image)\n",
    "        elif isinstance(image, torch.FloatTensor):\n",
    "            height, width = image.size(1),  image.size(2)\n",
    "        else:\n",
    "            raise Exception('Unknown type of image : {}'.format( type(image) ))\n",
    "        if xtarget.is_none() == False:\n",
    "            xtarget.apply_bound(width, height)\n",
    "            points = xtarget.points.copy()\n",
    "            points = torch.from_numpy(points.transpose((1,0))).type(torch.FloatTensor)\n",
    "            Hpoint = xtarget.points.copy()\n",
    "        else:\n",
    "            points = torch.from_numpy(np.zeros((self.NUM_PTS,3))).type(torch.FloatTensor)\n",
    "            Hpoint = self.NUM_PTS\n",
    "        if self.heatmap_type == 'laplacian':\n",
    "            target, mask = generate_label_map_laplacian(Hpoint, height//self.downsample, width//self.downsample, self.sigma, self.downsample, visible) # H*W*C\n",
    "        elif self.heatmap_type == 'gaussian':\n",
    "            target, mask = generate_label_map_gaussian(Hpoint, height//self.downsample, width//self.downsample, self.sigma, self.downsample, visible) # H*W*C\n",
    "        else:\n",
    "            raise Exception('Unknown type of image : {}'.format( type(image) ))\n",
    "        target = torch.from_numpy(target.transpose((2, 0, 1))).type(torch.FloatTensor)\n",
    "        mask   = torch.from_numpy(mask.transpose((2, 0, 1))).type(torch.ByteTensor)\n",
    "  \n",
    "        torch_index = torch.IntTensor([index])\n",
    "        torch_indicate = torch.ByteTensor( [ xtarget.is_none() == False ] )\n",
    "        return image, target, mask, points, torch_index, torch_indicate\n",
    "#     , ori_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/abhirup/Datasets/300W-Style/box-coords/300W-Original/300w.train.GTB'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
